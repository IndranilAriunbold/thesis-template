\chapter{Introduction}
\label{ch:intro}


The implementation of large language models (LLMs) on edge devices with limited resources introduces both unique opportunities and considerable challenges for autonomous control systems. This paper explores these challenges by demonstrating real-time intelligent control of a LEGO train using an agentic LLM with the ability to use a locally deployed custom tool on a Raspberry Pi. The system supports both text and voice inputs through an Automatic Speech Recognition (ASR) module, making the interaction more intuitive and hands-free.

The system is built around a decentralized architecture that relies on an asynchronous local communication protocol. This allows effective coordination between the AI agent, a separate Python program responsible for train motor control, and a graphical user interface (GUI) module. The GUI includes a real-time object detection feature, which plays a key role in handling emergency scenarios to ensure safer autonomous operation. The overall goal is to create a fully autonomous and responsive train system that can operate entirely offline, without relying on an internet connection. To achieve this, we build on recent developments in edge deployment of LLMs and lightweight frameworks that support tool-calling, including LangGraph, AutoAgent, and SmolAgents.

This project also continues and extends earlier student projects at the University of Applied Sciences in Darmstadt. One of the first teams managed to control a LEGO train using a Python script running on a Raspberry Pi, together with the LEGO Build HAT module connected to the train motor. They developed a basic user interface that could take pictures and videos and used MQTT to communicate with an Arduino-based track switch. Although this setup proved the feasibility of code-based remote control, it lacked more advanced automation features. A follow-up project introduced a color sensor to support conditional behavior, such as stopping at a green "signal" block, and implemented additional train commands like reversing and speed changes. However, this version was limited in two areas: visual feedback was missing from the GUI, and there was no inter-process communication, meaning the sensor data could not be used together with other input sources like obstacle detection. This research builds on and significantly enhances these previous efforts by integrating a locally running, reactive AI agent to manage control, perception, and decision-making tasks. To ensure compatibility with learning environments and further development, the system is based entirely on open-source tools.


%
% Section: Motivation
%
\section{Motivation}
\label{sec:intro:motivation}


Locally deployable, compact large language models combined with dedicated vision pipelines offer the possibility of real-time control through direct local communication, independent of the Internet. Raspberry Pi has long been a favorite among coders and educators due to its low cost and flexibility. It has played a huge role in introducing children and students to computing and electronics, often through hands-on projects like those developed during the KinderCampus workshops held annually at the University of Applied Sciences in Darmstadt. In these workshops, LEGO systems are used as a fun and interactive platform to teach programming and robotics to children of different age groups.

The growing capabilities of artificial intelligence and machine learning are now being integrated into a wide range of applications, from home automation to advanced robotics. Using a Raspberry Pi as a platform for running AI agents represents an affordable and adaptable approach that is accessible to students, hobbyists, and educators. With the increasing number of open-source libraries and frameworks available, it is becoming more feasible to experiment with technologies that were previously limited to powerful servers or cloud systems.

At the same time, recent studies in the field show that agentic LLMs, language models that can reason, plan, and call external tools, can now be deployed even in low-resource settings by applying various optimization techniques. Frameworks like TinyAgent and SmolAgents, for example, have demonstrated high tool-calling performance with quantized LLMs running locally. This means that even on hardware like the Raspberry Pi, it is now possible to build AI systems that can understand instructions, make decisions, and interact with other processes - all without need for a constant internet connection.

%
% Section: Ziele
%
\section{Research Objectives}
\label{sec:intro:goal}

The main goal of this project is to investigate and demonstrate how modern large language models (LLMs) can be effectively implemented in low-resource environments to create an autonomous and intelligent control system. This will be done through a combination of theoretical research and hands-on system development. More specifically, the project aims to show how smaller, optimized LLMs can still perform well under the constraints of limited memory and compute power, which is a common challenge in edge computing.

Deploying large LLMs on devices like smartphones or small embedded computers is usually not realistic due to their hardware limitations. Because of this, several model optimization techniques are used in this work. These include quantization, which lowers the precision of model weights to reduce memory usage; pruning, which removes unnecessary parameters from the network; and knowledge distillation, where a smaller "student" model learns from a larger "teacher" model. These techniques make it possible to run useful LLMs on devices like the Raspberry Pi without sacrificing too much performance.

The smart AI assistant developed in this project will be capable of running locally on a Raspberry Pi and managing a LEGO train using natural language commands. The Raspberry Pi is a widely used single-board computer that is both cost-effective and energy-efficient, but its limited processing power (typically a quad-core ARM CPU with 1GB to 8GB RAM) makes it a good test case for deploying optimized LLMs. On top of that, controlling the LEGO train adds a real-world, hands-on element to the challenge: the AI assistant will need to understand and execute commands like starting, stopping, changing direction, and adjusting speed. These actions will also be influenced by input from a real-time object detection module, which ensures that the system can react to obstacles and other dynamic situations on the track.

A key part of the architecture involves asynchronous communication between the different components, such as the LLM agent, the Python-based motor control, and the GUI. This makes it possible to integrate perception, control, and decision-making in a responsive and reliable way. The project aims not only to implement a working system but also to contribute a flexible and reproducible solution that can be used in educational or research contexts, especially where open-source tools and limited hardware are part of the setup.

%
% Section: Struktur der Arbeit
%
\section{Structure of the research paper}
\label{sec:intro:structure}
%Background, Related Work, Lit Review -> Gap, Problem Stement/Research question
In Chapter 2, we give you background information about the relevant topics, concepts, and technologies used to realize this project. In addition, as part of the literature review conducted, we will discuss related work to find research gaps. In the end, we will address these findings and outline the research question. 

% Actual implementation
In Chapter 3 we will discuss the system architecture of our proposed solution, highlighting the hardware and software requirements. In addition, in-depth discussion of our work will be provided to balance reproduction and further development of our implementation.

% Results and Analysis with limitations
In Chapter 4, we will discuss the limitations of our work and conclude our work in Chapter 5, summarizing our findings and giving you directions for future work.