\chapter{Einleitung}
\label{ch:intro}


This paper outlines the design and implementation of a reliable AI assistant utilizing the open source LangGraph ReAct framework by locally running large language models (LLM) with the ability to use a custom tool on a Raspberry Pi 4. The system incorporates both text and voice input features through Automatic Speech Recognition (ASR) and enables the control of a motorized LEGOÂ© train via a local communication protocol, ZeroMQ (ZMQ). The setup includes a separate Python program that manages the train control and a graphical user interface controller that facilitates real-time object detection, which is essential for emergency situation handling for safe autonomous vehicle operation. The goal is to create a fully autonomous and responsive train system operating independently of internet connectivity.

The integration of Large Language Models (LLMs) with Edge Intelligence (EI) is revolutionizing edge computing, enabling human-like language processing on resource-constrained devices (Friha et al., 2024). This aligns with the emerging field of TinyML, which allows machine learning models, including deep learning, to run on ultra-low-power IoT edge devices (Alajlan & Ibrahim, 2022). To address the challenges of deploying computationally expensive deep neural networks on edge devices with limited resources, researchers are exploring four main directions: novel architecture design, optimization of existing methods, algorithm-hardware codesign, and efficient accelerator development (Hossain Shuvo et al., 2023). These advancements aim to reduce latency, enhance security, and enable real-time decision-making at the edge. However, the implementation of LLM-based EI systems raises important considerations regarding security, optimization, and responsible development practices (Friha et al., 2024).

%
% Section: Motivation
%
\section{Motivation}
\label{sec:intro:motivation}
\graffito{Note: The content of this chapter is just some dummy text. It is not a real language.}

Locally deployable, compact large language models combined with dedicated vision pipelines enable real-time control through direct communication free of the Internet.

Raspberry Pi has always been a huge success in the coding community by actively introducing children into the computer science field from an early age. The use cases are numerous; implementation of practical projects enable full richness in usefulness to plain right joy. The success lays mainly in its features that are budget-friendly yet with the possibility to realize complex systems. 
With the rise of artificial intelligence becoming very capable and being incorporated in a number of different applications today, the need for personal usage rises. In particular, on small edge devices like raspberry pi and arduino. Furthermore, the usage of open source components makes it useful in small personal projects.

The ongoing evolution of artificial intelligence (AI) and machine learning creates new opportunities within robotics and automation. Specifically, the use of a Raspberry Pi as a platform for deploying AI systems provides a cost-effective and versatile solution that is accessible to a broad user base. The proposed LangGraph RAG ReAct agent combines open-source LLM capabilities with direct control functionalities to interact with the LEGO train system, utilizing voice commands and visual input for enhanced accessibility. 



At the University of Applied Sciences in Darmstadt, a annually held KinderCampus program is in place. It provides week-long workshops for coding for children of different age levels. They use LEGO systems to give hands-on experience. In this way, in the last two semesters, two different teams have executed small projects. First, they enabled the LEGO train to be controlled via the Python program, using Raspberry Pi with the Build Hat Module connected to the LEGO train motor. Alongside it they provided an graphical user interface, where you could not only control the train, but also use the connectes picamera to take pictures and record videos. In the last semester, their work has been enhanced by making the operation of the train smart, i.e. a color sensor unit has been connected to the raspberry pi to recognize colored papers along the train tracks. With this set up, the programm they developed, enabled the train to operate autonomously, that is to say, by determining what command it should execute depending on the detected color strip. This project was successful, but the LEGO Train could not be called truly smart. Therefore, we decided to enrich its capability by incorporating the capability of LLMs, building an AI Assistant for the train control.

The objective of the current study is to expand upon previous research by incorporating a set of opensource tools to overcome the limitations of the earlier framework. 

%
% Section: Ziele
%
\section{Ziel der Arbeit}
\label{sec:intro:goal}
Ready to use smart Assistant for a LEGO train to operate autonomously.
Our architecture employs LLMs without fine-tuning.

%
% Section: Struktur der Arbeit
%
\section{Gliederung}
\label{sec:intro:structure}
In Chapter 2, we give you some background information and the technologies used. In addition, related works will be discussed to find research gaps.
The method used to find relevant works will be addressed.

In Chapter 3 we will discuss the system architecture of our proposed solution, highlighting the hardware and software requirements. In addition, in-depth discussion of our work will be provided to balance reproduction and further development of our implementation.

In Chapter 4, we will discuss the limitations of our work and conclude our work in Chapter 5.