\chapter{Introduction}
\label{ch:intro}

\graffito{TODO: for Abstact}
%This paper outlines the design and implementation of a reliable AI assistant utilizing the open source LangGraph ReAct framework by locally running large language models (LLM) with the ability to use a custom tool on a Raspberry Pi 4. The system incorporates both text and voice input features through Automatic Speech Recognition (ASR) and enables the control of a motorized LEGOÂ© train via a local communication protocol, ZeroMQ (ZMQ). The setup includes a separate Python program that manages the train motor control and a graphical user interface controller that facilitates real-time object detection, which is essential for handling emergency situations for safe autonomous vehicle operation. The goal is to create a fully autonomous and responsive train system that operates independently of the internet connectivity.

%The implementation of large language models (LLMs) on edge devices with limited resources introduces both unique opportunities and considerable challenges for autonomous control systems. This paper explores these challenges by offering real-time intelligent control of a LEGO train through an agentic LLM with the ability to use a custom tool, which is locally deployed on a Raspberry Pi. The system incorporates both text and voice input features through Automatic Speech Recognition (ASR).
%The proposed system design features a decentralized architecture supported by asynchronous local communication protocol to provide effective interaction between the AI agent, a separate Python program that manages the train motor control, and a graphical user interface (UI) module. The latter facilitates real-time object detection, which is essential for handling emergency situations for safe autonomous vehicle operation. The goal is to create a fully autonomous and responsive train system that operates independently of the internet connectivity.

The implementation of large language models (LLMs) on edge devices with limited resources introduces both unique opportunities and considerable challenges for autonomous control systems. This paper explores these challenges by demonstrating real-time intelligent control of a LEGO train using an agentic LLM with the ability to use a locally deployed custom tool on a Raspberry Pi. The system supports both text and voice inputs through an Automatic Speech Recognition (ASR) module, making the interaction more intuitive and hands-free.

The system is built around a decentralized architecture that relies on an asynchronous local communication protocol. This allows effective coordination between the AI agent, a separate Python program responsible for train motor control, and a graphical user interface (GUI) module. The GUI includes a real-time object detection feature, which plays a key role in handling emergency scenarios to ensure safer autonomous operation. The overall goal is to create a fully autonomous and responsive train system that can operate entirely offline, without relying on an internet connection. To achieve this, we build on recent developments in edge deployment of LLMs and lightweight frameworks that support tool-calling, including LangGraph, AutoAgent, and SmolAgents.

This project also continues and extends earlier student projects at the University of Applied Sciences in Darmstadt. One of the first teams managed to control a LEGO train using a Python script running on a Raspberry Pi, together with the LEGO Build HAT module connected to the train motor. They developed a basic user interface that could take pictures and videos and used MQTT to communicate with an Arduino-based track switch. Although this setup proved the feasibility of code-based remote control, it lacked more advanced automation features. A follow-up project introduced a color sensor to support conditional behavior, such as stopping at a green "signal" block, and implemented additional train commands like reversing and speed changes. However, this version was limited in two areas: visual feedback was missing from the GUI, and there was no inter-process communication, meaning the sensor data could not be used together with other input sources like obstacle detection. This research builds on and significantly enhances these previous efforts by integrating a locally running, reactive AI agent to manage control, perception, and decision-making tasks. To ensure compatibility with learning environments and further development, the system is based entirely on open-source tools.

% This approach is crucial to preserve system responsiveness, even when individual components experience temporary delays or failures, which is a common issue in environments with limited resources. Asynchronous communication, realized through message queues via ZeroMQ, lets the graphical interface retain its responsiveness to user inputs even if the LLM is engaged in a complex reasoning task.

%
% Section: Motivation
%
\section{Motivation}
\label{sec:intro:motivation}


%Locally deployable, compact large language models combined with dedicated vision pipelines enable real-time control through direct communication free of the Internet. Raspberry Pi has always been a huge success in the coding community by actively introducing children into the computer science field from an early age. The use cases are numerous; implementation of practical projects enable full richness in usefulness to plain right joy. The success lays mainly in its features that are budget-friendly yet with the possibility to realize complex systems. 
%The ongoing evolution of artificial intelligence (AI) and machine learning becoming very capable creates not only new opportunities within robotics and automation; it is incorporated in a number of different applications today.  Specifically, the use of a Raspberry Pi as a platform for deploying AI systems provides a cost-effective and versatile solution that is accessible to a broad user base, furthermore, by the rising number of open source solutions. 
%The University of Applied Sciences in Darmstadt annually held a KinderCampus program. It provides week-long workshops for coding for children of different age levels. They use LEGO systems to give hands-on experience.  Previous teams of students from the University of Applied Sciences in Darmstadt successfully implemented LEGO train enhancement projects. The first team enabled the LEGO train to be controlled via  Python program, using Raspberry Pi with the Build Hat Module connected to the LEGO train motor.  The initial project developed a user interface that included basic picture and video recording and used MQTT for communication with an Arduino-operated track switch. This fundamental technology demonstrated potential for code-based remote control, but lacked advanced automation capabilities. 
%The following effort of a second team added a color sensor module to the raspberry Pi to enable conditional train operations, including starting, halting, speed adjustment, and direction change; however, it was limited in visual feedback and inter-process communication. For example, while the color sensor might have been used to stop the train at a green "signal" block, the lack of visual feedback in the GUI resulted in users receiving no assurance that the train had stopped at the specified place. The absence of inter-process communication restricted the integration of color sensor data with alternative control mechanisms, including obstacle detection. This research advances and substantially improves previous work by integrating a reactive independent AI agent. For this we want to use set of open source tools, so that our results can be integrated into the study environment.

Locally deployable, compact large language models combined with dedicated vision pipelines offer the possibility of real-time control through direct local communication, independent of the Internet. Raspberry Pi has long been a favorite among coders and educators due to its low cost and flexibility. It has played a huge role in introducing children and students to computing and electronics, often through hands-on projects like those developed during the KinderCampus workshops held annually at the University of Applied Sciences in Darmstadt. In these workshops, LEGO systems are used as a fun and interactive platform to teach programming and robotics to children of different age groups.

The growing capabilities of artificial intelligence and machine learning are now being integrated into a wide range of applications, from home automation to advanced robotics. Using a Raspberry Pi as a platform for running AI agents represents an affordable and adaptable approach that is accessible to students, hobbyists, and educators. With the increasing number of open-source libraries and frameworks available, it is becoming more feasible to experiment with technologies that were previously limited to powerful servers or cloud systems.

At the same time, recent studies in the field show that agentic LLMs, language models that can reason, plan, and call external tools, can now be deployed even in low-resource settings by applying various optimization techniques. Frameworks like TinyAgent and SmolAgents, for example, have demonstrated high tool-calling performance with quantized LLMs running locally. This means that even on hardware like the Raspberry Pi, it is now possible to build AI systems that can understand instructions, make decisions, and interact with other processes - all without need for a constant internet connection.

%
% Section: Ziele
%
\section{Research Objectives}
\label{sec:intro:goal}
%The primary objective of this project is to investigate and demonstrate the effective implementation of contemporary large language models (LLMs) in low-resource environments to build an autonomous intelligent control system. This will be accomplished through practical implementation and comprehensive theoretical analysis. The study examines how a smaller and refined LLM can achieve performance comparable to a larger model considering constraints in computational resources and memory. This is particularly relevant in edge computing scenarios where resources are limited and latency is a crucial factor. Deploying large-scale LLM on devices like smartphones or tiny embedded computers is often not feasible due to hardware limitations. Consequently, techniques such as information distillation, pruning, and quantization can be used to generate smaller, more efficient models without compromising accuracy. Knowledge distillation entails teaching a concise "student" model to emulate the performance of a larger, elaborate "teacher" model. Pruning eliminates less essential connections in the neural network, thus decreasing its size and computing requirements. Quantization reduces the precision of the model's weights, thus lowering memory consumption and accelerating inference. The goal of the present work involves the design and implementation of a smart AI assistant that functions locally on a Raspberry Pi, a popular single-board computer known for its cost-effectiveness and energy economy, to manage a LEGO train using natural language commands. This project demonstrates the capabilities of fine-tuned LLMs in resource-constrained contexts. The Raspberry Pi, characterized by limited processing capabilities and memory (usually ranging from 1GB to 8GB of RAM and equipped with a quad-core ARM CPU), creates a major challenge for the setting up of an advanced AI system. Furthermore, managing a LEGO train introduces a practical aspect, which requires the AI assistant to comprehend and execute commands related to speed, direction, and stopping, thus demonstrating its proficiency.
The main goal of this project is to investigate and demonstrate how modern large language models (LLMs) can be effectively implemented in low-resource environments to create an autonomous and intelligent control system. This will be done through a combination of theoretical research and hands-on system development. More specifically, the project aims to show how smaller, optimized LLMs can still perform well under the constraints of limited memory and compute power, which is a common challenge in edge computing.

Deploying large LLMs on devices like smartphones or small embedded computers is usually not realistic due to their hardware limitations. Because of this, several model optimization techniques are used in this work. These include quantization, which lowers the precision of model weights to reduce memory usage; pruning, which removes unnecessary parameters from the network; and knowledge distillation, where a smaller "student" model learns from a larger "teacher" model. These techniques make it possible to run useful LLMs on devices like the Raspberry Pi without sacrificing too much performance.

The smart AI assistant developed in this project will be capable of running locally on a Raspberry Pi and managing a LEGO train using natural language commands. The Raspberry Pi is a widely used single-board computer that is both cost-effective and energy-efficient, but its limited processing power (typically a quad-core ARM CPU with 1GB to 8GB RAM) makes it a good test case for deploying optimized LLMs. On top of that, controlling the LEGO train adds a real-world, hands-on element to the challenge: the AI assistant will need to understand and execute commands like starting, stopping, changing direction, and adjusting speed. These actions will also be influenced by input from a real-time object detection module, which ensures that the system can react to obstacles and other dynamic situations on the track.

A key part of the architecture involves asynchronous communication between the different components, such as the LLM agent, the Python-based motor control, and the GUI. This makes it possible to integrate perception, control, and decision-making in a responsive and reliable way. The project aims not only to implement a working system but also to contribute a flexible and reproducible solution that can be used in educational or research contexts, especially where open-source tools and limited hardware are part of the setup.

%
% Section: Struktur der Arbeit
%
\section{Structure of the research paper}
\label{sec:intro:structure}
%Background, Related Work, Lit Review -> Gap, Problem Stement/Research question
In Chapter 2, we give you background information about the relevant topics, concepts, and technologies used to realize this project. In addition, as part of the literature review conducted, we will discuss related work to find research gaps. In the end, we will address these findings and outline the research question. 

% Actual implementation
In Chapter 3 we will discuss the system architecture of our proposed solution, highlighting the hardware and software requirements. In addition, in-depth discussion of our work will be provided to balance reproduction and further development of our implementation.

% Results and Analysis with limitations
In Chapter 4, we will discuss the limitations of our work and conclude our work in Chapter 5, summarizing our findings and giving you directions for future work.